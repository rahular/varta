{
    "model_name_or_path": "varta/t5-base-1M",
    "dataset_name": "ai4bharat/IndicSentenceSummarization",
    "text_column": "input",
    "summary_column": "target",
    "lang": "all",
    "overwrite_cache": true,
    "preprocessing_num_workers": 4,
    "max_source_length": 512,
    "max_target_length": 64,
    "val_max_target_length": 64,
    "pad_to_max_length": false,
    "max_train_samples": null,
    "max_eval_samples": 10000,
    "max_predict_samples": null,
    "num_beams": 4,
    "ignore_pad_token_for_loss": true,
    "use_fast_tokenizer": false,
    "output_dir": "models/varta-t5-1M-sentsum-run2",
    "overwrite_output_dir": false,
    "do_train": true,
    "do_eval": true,
    "do_predict": true,
    "evaluation_strategy": "steps",
    "per_device_train_batch_size": 64,
    "per_device_eval_batch_size": 64,
    "gradient_accumulation_steps": 4,
    "eval_delay": 0,
    "learning_rate": 5e-05,
    "weight_decay": 0.0,
    "adam_beta1": 0.9,
    "adam_beta2": 0.999,
    "adam_epsilon": 1e-06,
    "max_steps": 50000,
    "lr_scheduler_type": "linear",
    "warmup_steps": 500,
    "log_level": "info",
    "logging_strategy": "steps",
    "logging_first_step": true,
    "logging_steps": 500,
    "save_strategy": "steps",
    "save_steps": 500,
    "save_total_limit": 5,
    "seed": 42,
    "data_seed": 42,
    "fp16": false,
    "eval_steps": 500,
    "dataloader_num_workers": 4,
    "load_best_model_at_end": true,
    "metric_for_best_model": "rougeL",
    "greater_is_better": true,
    "optim": "adamw_bnb_8bit",
    "ddp_find_unused_parameters": false,
    "ddp_timeout": 172800,
    "report_to": "wandb",
    "run_name": "varta-t5-1M-sentsum",
    "skip_memory_metrics": false,
    "auto_find_batch_size": true,
    "predict_with_generate": true
}
